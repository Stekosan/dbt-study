{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install duckdb\n",
    "#%pip install dbt-duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sqlfluff\n",
      "  Downloading sqlfluff-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting appdirs (from sqlfluff)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting chardet (from sqlfluff)\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: click in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sqlfluff) (8.1.7)\n",
      "Requirement already satisfied: colorama>=0.3 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sqlfluff) (0.4.6)\n",
      "Collecting diff-cover>=2.5.0 (from sqlfluff)\n",
      "  Downloading diff_cover-9.2.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: Jinja2 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sqlfluff) (3.1.3)\n",
      "Requirement already satisfied: pathspec in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sqlfluff) (0.12.1)\n",
      "Collecting pytest (from sqlfluff)\n",
      "  Downloading pytest-8.3.3-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sqlfluff) (6.0.1)\n",
      "Requirement already satisfied: regex in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sqlfluff) (2024.4.16)\n",
      "Collecting tblib (from sqlfluff)\n",
      "  Downloading tblib-3.0.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sqlfluff) (4.66.2)\n",
      "Requirement already satisfied: Pygments<3.0.0,>=2.9.0 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from diff-cover>=2.5.0->sqlfluff) (2.17.2)\n",
      "Collecting pluggy<2,>=0.13.1 (from diff-cover>=2.5.0->sqlfluff)\n",
      "  Using cached pluggy-1.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Jinja2->sqlfluff) (2.1.5)\n",
      "Collecting iniconfig (from pytest->sqlfluff)\n",
      "  Downloading iniconfig-2.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pytest->sqlfluff) (24.0)\n",
      "Downloading sqlfluff-3.2.0-py3-none-any.whl (820 kB)\n",
      "   ---------------------------------------- 0.0/820.4 kB ? eta -:--:--\n",
      "   ------ --------------------------------- 143.4/820.4 kB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  809.0/820.4 kB 8.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 820.4/820.4 kB 7.4 MB/s eta 0:00:00\n",
      "Downloading diff_cover-9.2.0-py3-none-any.whl (52 kB)\n",
      "   ---------------------------------------- 0.0/52.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 52.6/52.6 kB 2.8 MB/s eta 0:00:00\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "   ---------------------------------------- 0.0/199.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 199.4/199.4 kB 12.6 MB/s eta 0:00:00\n",
      "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading pytest-8.3.3-py3-none-any.whl (342 kB)\n",
      "   ---------------------------------------- 0.0/342.3 kB ? eta -:--:--\n",
      "   --------------------------------------- 342.3/342.3 kB 22.1 MB/s eta 0:00:00\n",
      "Downloading tblib-3.0.0-py3-none-any.whl (12 kB)\n",
      "Using cached pluggy-1.5.0-py3-none-any.whl (20 kB)\n",
      "Downloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Installing collected packages: appdirs, tblib, pluggy, iniconfig, chardet, pytest, diff-cover, sqlfluff\n",
      "Successfully installed appdirs-1.4.4 chardet-5.2.0 diff-cover-9.2.0 iniconfig-2.0.0 pluggy-1.5.0 pytest-8.3.3 sqlfluff-3.2.0 tblib-3.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#%pip install sqlfluff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Cell magic `%%SQL` not found.\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: sqlfluff\n",
      "Version: 3.2.0\n",
      "Summary: The SQL Linter for Humans\n",
      "Home-page: https://www.sqlfluff.com\n",
      "Author: \n",
      "Author-email: Alan Cruickshank <alan@designingoverload.com>\n",
      "License: MIT License\n",
      "\n",
      "Copyright (c) 2023 Alan Cruickshank\n",
      "\n",
      "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
      "of this software and associated documentation files (the \"Software\"), to deal\n",
      "in the Software without restriction, including without limitation the rights\n",
      "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
      "copies of the Software, and to permit persons to whom the Software is\n",
      "furnished to do so, subject to the following conditions:\n",
      "\n",
      "The above copyright notice and this permission notice shall be included in all\n",
      "copies or substantial portions of the Software.\n",
      "\n",
      "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
      "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
      "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
      "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
      "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
      "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
      "SOFTWARE.\n",
      "\n",
      "Location: c:\\Users\\Steve\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\n",
      "Requires: appdirs, chardet, click, colorama, diff-cover, Jinja2, pathspec, pytest, pyyaml, regex, tblib, tqdm\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show sqlfluff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dbt-duckdb in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.8.1)\n",
      "Collecting dbt-duckdb\n",
      "  Downloading dbt_duckdb-1.8.4-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: dbt-common<2,>=1 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-duckdb) (1.5.0)\n",
      "Requirement already satisfied: dbt-adapters<2,>=1 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-duckdb) (1.3.2)\n",
      "Requirement already satisfied: duckdb>=1.0.0 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-duckdb) (1.0.0)\n",
      "Requirement already satisfied: dbt-core>=1.8.0 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-duckdb) (1.8.3)\n",
      "Requirement already satisfied: agate<2.0,>=1.0 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-adapters<2,>=1->dbt-duckdb) (1.9.1)\n",
      "Requirement already satisfied: mashumaro<4.0,>=3.0 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mashumaro[msgpack]<4.0,>=3.0->dbt-adapters<2,>=1->dbt-duckdb) (3.13.1)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.0 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-adapters<2,>=1->dbt-duckdb) (4.25.3)\n",
      "Requirement already satisfied: pytz>=2015.7 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-adapters<2,>=1->dbt-duckdb) (2024.1)\n",
      "Requirement already satisfied: typing-extensions<5.0,>=4.0 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-adapters<2,>=1->dbt-duckdb) (4.12.2)\n",
      "Requirement already satisfied: colorama<0.5,>=0.3.9 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-common<2,>=1->dbt-duckdb) (0.4.6)\n",
      "Requirement already satisfied: deepdiff<8.0,>=7.0 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-common<2,>=1->dbt-duckdb) (7.0.1)\n",
      "Requirement already satisfied: isodate<0.7,>=0.6 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-common<2,>=1->dbt-duckdb) (0.6.1)\n",
      "Requirement already satisfied: jinja2<4,>=3.1.3 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-common<2,>=1->dbt-duckdb) (3.1.3)\n",
      "Requirement already satisfied: jsonschema<5.0,>=4.0 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-common<2,>=1->dbt-duckdb) (4.22.0)\n",
      "Requirement already satisfied: pathspec<0.13,>=0.9 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-common<2,>=1->dbt-duckdb) (0.12.1)\n",
      "Requirement already satisfied: python-dateutil<3.0,>=2.0 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-common<2,>=1->dbt-duckdb) (2.9.0.post0)\n",
      "Requirement already satisfied: requests<3.0.0 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-common<2,>=1->dbt-duckdb) (2.31.0)\n",
      "Requirement already satisfied: logbook<1.6,>=1.5 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-core>=1.8.0->dbt-duckdb) (1.5.3)\n",
      "Requirement already satisfied: click<9.0,>=8.0.2 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-core>=1.8.0->dbt-duckdb) (8.1.7)\n",
      "Requirement already satisfied: networkx<4.0,>=2.3 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-core>=1.8.0->dbt-duckdb) (3.3)\n",
      "Requirement already satisfied: sqlparse<0.6.0,>=0.5.0 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-core>=1.8.0->dbt-duckdb) (0.5.0)\n",
      "Requirement already satisfied: dbt-extractor<=0.6,>=0.5.0 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-core>=1.8.0->dbt-duckdb) (0.5.1)\n",
      "Requirement already satisfied: minimal-snowplow-tracker<0.1,>=0.0.2 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-core>=1.8.0->dbt-duckdb) (0.0.2)\n",
      "Requirement already satisfied: dbt-semantic-interfaces<0.6,>=0.5.1 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-core>=1.8.0->dbt-duckdb) (0.5.1)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-core>=1.8.0->dbt-duckdb) (24.0)\n",
      "Requirement already satisfied: pyyaml>=6.0 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-core>=1.8.0->dbt-duckdb) (6.0.1)\n",
      "Requirement already satisfied: daff>=1.3.46 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-core>=1.8.0->dbt-duckdb) (1.3.46)\n",
      "Requirement already satisfied: Babel>=2.0 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from agate<2.0,>=1.0->dbt-adapters<2,>=1->dbt-duckdb) (2.15.0)\n",
      "Requirement already satisfied: leather>=0.3.2 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from agate<2.0,>=1.0->dbt-adapters<2,>=1->dbt-duckdb) (0.4.0)\n",
      "Requirement already satisfied: parsedatetime!=2.5,>=2.1 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from agate<2.0,>=1.0->dbt-adapters<2,>=1->dbt-duckdb) (2.6)\n",
      "Requirement already satisfied: python-slugify>=1.2.1 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from agate<2.0,>=1.0->dbt-adapters<2,>=1->dbt-duckdb) (8.0.4)\n",
      "Requirement already satisfied: pytimeparse>=1.1.5 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from agate<2.0,>=1.0->dbt-adapters<2,>=1->dbt-duckdb) (1.1.8)\n",
      "Requirement already satisfied: tzdata>=2023.3 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from agate<2.0,>=1.0->dbt-adapters<2,>=1->dbt-duckdb) (2024.1)\n",
      "Requirement already satisfied: importlib-metadata<7,>=6.0 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-semantic-interfaces<0.6,>=0.5.1->dbt-core>=1.8.0->dbt-duckdb) (6.11.0)\n",
      "Requirement already satisfied: more-itertools<11.0,>=8.0 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-semantic-interfaces<0.6,>=0.5.1->dbt-core>=1.8.0->dbt-duckdb) (10.3.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.10 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-semantic-interfaces<0.6,>=0.5.1->dbt-core>=1.8.0->dbt-duckdb) (2.8.2)\n",
      "Requirement already satisfied: ordered-set<4.2.0,>=4.1.0 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from deepdiff<8.0,>=7.0->dbt-common<2,>=1->dbt-duckdb) (4.1.0)\n",
      "Requirement already satisfied: six in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from isodate<0.7,>=0.6->dbt-common<2,>=1->dbt-duckdb) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2<4,>=3.1.3->dbt-common<2,>=1->dbt-duckdb) (2.1.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema<5.0,>=4.0->dbt-common<2,>=1->dbt-duckdb) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema<5.0,>=4.0->dbt-common<2,>=1->dbt-duckdb) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema<5.0,>=4.0->dbt-common<2,>=1->dbt-duckdb) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema<5.0,>=4.0->dbt-common<2,>=1->dbt-duckdb) (0.18.1)\n",
      "Requirement already satisfied: msgpack>=0.5.6 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mashumaro[msgpack]<4.0,>=3.0->dbt-adapters<2,>=1->dbt-duckdb) (1.0.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0->dbt-common<2,>=1->dbt-duckdb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0->dbt-common<2,>=1->dbt-duckdb) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0->dbt-common<2,>=1->dbt-duckdb) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0->dbt-common<2,>=1->dbt-duckdb) (2024.2.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from importlib-metadata<7,>=6.0->dbt-semantic-interfaces<0.6,>=0.5.1->dbt-core>=1.8.0->dbt-duckdb) (3.19.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.10->dbt-semantic-interfaces<0.6,>=0.5.1->dbt-core>=1.8.0->dbt-duckdb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.10->dbt-semantic-interfaces<0.6,>=0.5.1->dbt-core>=1.8.0->dbt-duckdb) (2.20.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-slugify>=1.2.1->agate<2.0,>=1.0->dbt-adapters<2,>=1->dbt-duckdb) (1.3)\n",
      "Downloading dbt_duckdb-1.8.4-py3-none-any.whl (62 kB)\n",
      "   ---------------------------------------- 0.0/62.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 62.5/62.5 kB ? eta 0:00:00\n",
      "Installing collected packages: dbt-duckdb\n",
      "  Attempting uninstall: dbt-duckdb\n",
      "    Found existing installation: dbt-duckdb 1.8.1\n",
      "    Uninstalling dbt-duckdb-1.8.1:\n",
      "      Successfully uninstalled dbt-duckdb-1.8.1\n",
      "Successfully installed dbt-duckdb-1.8.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#%pip install --upgrade dbt-duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: dbt-core in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.8.3)\n",
      "Collecting dbt-core\n",
      "  Downloading dbt_core-1.8.7-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: agate<1.10,>=1.7.0 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-core) (1.9.1)\n",
      "Requirement already satisfied: Jinja2<4,>=3.1.3 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-core) (3.1.3)\n",
      "Requirement already satisfied: mashumaro<4.0,>=3.9 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mashumaro[msgpack]<4.0,>=3.9->dbt-core) (3.13.1)\n",
      "Requirement already satisfied: logbook<1.6,>=1.5 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-core) (1.5.3)\n",
      "Requirement already satisfied: click<9.0,>=8.0.2 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-core) (8.1.7)\n",
      "Requirement already satisfied: networkx<4.0,>=2.3 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-core) (3.3)\n",
      "Requirement already satisfied: protobuf<5,>=4.0.0 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-core) (4.25.3)\n",
      "Requirement already satisfied: requests<3.0.0 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-core) (2.31.0)\n",
      "Requirement already satisfied: pathspec<0.13,>=0.9 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-core) (0.12.1)\n",
      "Requirement already satisfied: sqlparse<0.6.0,>=0.5.0 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-core) (0.5.0)\n",
      "Requirement already satisfied: dbt-extractor<=0.6,>=0.5.0 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-core) (0.5.1)\n",
      "Requirement already satisfied: minimal-snowplow-tracker<0.1,>=0.0.2 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-core) (0.0.2)\n",
      "Requirement already satisfied: dbt-semantic-interfaces<0.6,>=0.5.1 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-core) (0.5.1)\n",
      "Requirement already satisfied: dbt-common<2.0,>=1.0.4 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-core) (1.5.0)\n",
      "Requirement already satisfied: dbt-adapters<2.0,>=1.1.1 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-core) (1.3.2)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-core) (24.0)\n",
      "Requirement already satisfied: pytz>=2015.7 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-core) (2024.1)\n",
      "Requirement already satisfied: pyyaml>=6.0 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-core) (6.0.1)\n",
      "Requirement already satisfied: daff>=1.3.46 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-core) (1.3.46)\n",
      "Requirement already satisfied: typing-extensions>=4.4 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-core) (4.12.2)\n",
      "Requirement already satisfied: Babel>=2.0 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from agate<1.10,>=1.7.0->dbt-core) (2.15.0)\n",
      "Requirement already satisfied: isodate>=0.5.4 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from agate<1.10,>=1.7.0->dbt-core) (0.6.1)\n",
      "Requirement already satisfied: leather>=0.3.2 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from agate<1.10,>=1.7.0->dbt-core) (0.4.0)\n",
      "Requirement already satisfied: parsedatetime!=2.5,>=2.1 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from agate<1.10,>=1.7.0->dbt-core) (2.6)\n",
      "Requirement already satisfied: python-slugify>=1.2.1 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from agate<1.10,>=1.7.0->dbt-core) (8.0.4)\n",
      "Requirement already satisfied: pytimeparse>=1.1.5 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from agate<1.10,>=1.7.0->dbt-core) (1.1.8)\n",
      "Requirement already satisfied: tzdata>=2023.3 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from agate<1.10,>=1.7.0->dbt-core) (2024.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click<9.0,>=8.0.2->dbt-core) (0.4.6)\n",
      "Requirement already satisfied: deepdiff<8.0,>=7.0 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-common<2.0,>=1.0.4->dbt-core) (7.0.1)\n",
      "Requirement already satisfied: jsonschema<5.0,>=4.0 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-common<2.0,>=1.0.4->dbt-core) (4.22.0)\n",
      "Requirement already satisfied: python-dateutil<3.0,>=2.0 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-common<2.0,>=1.0.4->dbt-core) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-metadata<7,>=6.0 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-semantic-interfaces<0.6,>=0.5.1->dbt-core) (6.11.0)\n",
      "Requirement already satisfied: more-itertools<11.0,>=8.0 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-semantic-interfaces<0.6,>=0.5.1->dbt-core) (10.3.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.10 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dbt-semantic-interfaces<0.6,>=0.5.1->dbt-core) (2.8.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Jinja2<4,>=3.1.3->dbt-core) (2.1.5)\n",
      "Requirement already satisfied: msgpack>=0.5.6 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from mashumaro[msgpack]<4.0,>=3.9->dbt-core) (1.0.8)\n",
      "Requirement already satisfied: six<2.0,>=1.9.0 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from minimal-snowplow-tracker<0.1,>=0.0.2->dbt-core) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0->dbt-core) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0->dbt-core) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0->dbt-core) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3.0.0->dbt-core) (2024.2.2)\n",
      "Requirement already satisfied: ordered-set<4.2.0,>=4.1.0 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from deepdiff<8.0,>=7.0->dbt-common<2.0,>=1.0.4->dbt-core) (4.1.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from importlib-metadata<7,>=6.0->dbt-semantic-interfaces<0.6,>=0.5.1->dbt-core) (3.19.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema<5.0,>=4.0->dbt-common<2.0,>=1.0.4->dbt-core) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema<5.0,>=4.0->dbt-common<2.0,>=1.0.4->dbt-core) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema<5.0,>=4.0->dbt-common<2.0,>=1.0.4->dbt-core) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema<5.0,>=4.0->dbt-common<2.0,>=1.0.4->dbt-core) (0.18.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.10->dbt-semantic-interfaces<0.6,>=0.5.1->dbt-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pydantic<3,>=1.10->dbt-semantic-interfaces<0.6,>=0.5.1->dbt-core) (2.20.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-slugify>=1.2.1->agate<1.10,>=1.7.0->dbt-core) (1.3)\n",
      "Downloading dbt_core-1.8.7-py3-none-any.whl (900 kB)\n",
      "   ---------------------------------------- 0.0/900.5 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 61.4/900.5 kB 3.2 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 143.4/900.5 kB 2.1 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 225.3/900.5 kB 2.0 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 307.2/900.5 kB 1.9 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 389.1/900.5 kB 1.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 471.0/900.5 kB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 563.2/900.5 kB 1.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 655.4/900.5 kB 1.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 778.2/900.5 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  880.6/900.5 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 900.5/900.5 kB 2.0 MB/s eta 0:00:00\n",
      "Installing collected packages: dbt-core\n",
      "  Attempting uninstall: dbt-core\n",
      "    Found existing installation: dbt-core 1.8.3\n",
      "    Uninstalling dbt-core-1.8.3:\n",
      "      Successfully uninstalled dbt-core-1.8.3\n",
      "Successfully installed dbt-core-1.8.7\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.2 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#%pip install --upgrade dbt-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: duckdb\n",
      "Version: 1.0.0\n",
      "Summary: DuckDB in-process database\n",
      "Home-page: https://www.duckdb.org\n",
      "Author: \n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: c:\\Users\\Steve\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\n",
      "Requires: \n",
      "Required-by: dbt-duckdb\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: dbt-duckdb\n",
      "Version: 1.8.1\n",
      "Summary: The duckdb adapter plugin for dbt (data build tool)\n",
      "Home-page: https://github.com/jwills/dbt-duckdb\n",
      "Author: Josh Wills\n",
      "Author-email: joshwills+dbt@gmail.com\n",
      "License: \n",
      "Location: c:\\Users\\Steve\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\n",
      "Requires: dbt-adapters, dbt-common, dbt-core, duckdb\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show dbt-duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in c:\\users\\steve\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pyspark) (0.10.9.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#%pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: pyspark\n",
      "Version: 3.5.1\n",
      "Summary: Apache Spark Python API\n",
      "Home-page: https://github.com/apache/spark/tree/master/python\n",
      "Author: Spark Developers\n",
      "Author-email: dev@spark.apache.org\n",
      "License: http://www.apache.org/licenses/LICENSE-2.0\n",
      "Location: c:\\Users\\Steve\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\n",
      "Requires: py4j\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip show pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Creating a dbt project\n",
    "Welcome back! We've learned a little about dbt as a tool and a command-line application, but let's now discuss dbt projects and how they're used.\n",
    "\n",
    "## 2. What is a dbt project\n",
    "So what is a project in the context of dbt? Projects encompass all the needed (and optional) components for working with data within dbt. \n",
    "\n",
    "The project configuration includes the project name, folder names, etc. Data sources and destinations, such as where the source data comes from, as well as any destination data warehouses. \n",
    "dbt projects also include the SQL queries and templates that define how to access and transform the data into the desired formats. A dbt project can also include documentation for the data and the relationships within it. It's important to note that a dbt project is implemented as a folder structure on a given machine. As such, it can be easily copied, modified, or placed into source control as needed. We'll cover each of these further in this and later chapters.\n",
    "\n",
    "## 3. How to create a new project\n",
    "The next question is how do we actually create a project within dbt. This is accomplished with the `dbt init` subcommand.\n",
    "When running dbt init, it typically asks two questions: the name of the project and which database or data warehouse type you'd like to use. \n",
    "\n",
    "You can consolidate the command line entry as dbt init projectname, which will then only ask for the database type. dbt init will then create the top-level project folder and subfolders and configuration files for the project. Here is a quick example of running dbt init with a project name of test_project and using duckdb as our database type.\n",
    "\n",
    "## 4. Defining configuration with project profiles\n",
    "The next thing to understand about dbt projects is the idea of a profile. Within dbt, a profile is most analogous to a given deployment scenario. This can include development, staging or testing, and production. \n",
    "\n",
    "Each profile can be defined as the user sees fit. Multiple profiles can exist within a given dbt project, allowing for different warehouse configurations based on the deployment scenario. These profiles (ie, configurations) are defined in the profiles.yml (or profiles dot yaml) file, which is not automatically created on a new project. This is an example profiles.yml file with two deployment types (dev and prod), and the default, as set by the option target, is currently set to dev. You may also be wondering why to select DuckDB vs Snowflake for either scenario. DuckDB is useful for development and testing locally, while Snowflake would be better used in production as other users will likely need to access the data.\n",
    "\n",
    "## 5. YAML\n",
    "Depending on your experience, you may be wondering what YAML is. YAML stands for Yet Another Markup Language. It is a text based file format, but whitespace indentation matters, much like Python. YAML is used in many development scenarios, often for configuration, due to its relatively human-readable format. The rules for writing or modifying YAML can be tricky, but maintain indentation as illustrated in examples. You can see this in the profiles.yml example, where dev: and prod: are at the same level of indentation. A YAML skeleton will be provided in this course, but be aware of the formatting requirements if you need to create one from scratch.\n",
    "\n",
    "## 6. DuckDB\n",
    "Another term you may have noticed is DuckDB. DuckDB is an open-source serverless database, similar to sqlite. This means there is not a server process required, in contrast to postgresql or mysql. It is designed for analytics, ie, data warehouses, and is fast due to its vectorized nature. We're using DuckDB in this course as it's easy to use, and works with dbt, thanks to the dbt-duckdb adapter. We won't cover much about DuckDB, but note that you can access DuckDB easily on your computer or in a DataCamp Workspace.\n",
    "\n",
    "## 7. Let's Practice!\n",
    "Let's take what we've learned and create our first dbt project in the exercises ahead. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Working with a first project\n",
    "We've reached the last video of the chapter! Let's look at the process for working with your dbt project(s).\n",
    "\n",
    "## 2. Workflow for dbt\n",
    "A workflow for dbt depends somewhat on the user's needs, but typically follows as First, create the project using dbt init (or copy a working project from another location) \n",
    "Next, define or update its configuration in the profiles.yml file. We've already done these steps. \n",
    "The next step, and where you'll spend most of your time developing with dbt, is defining and using the data models. We'll go over what a model represents more in the next chapter. \n",
    "For now, it's basically the transformed version(s) of your data that you wish to make accessible in the data warehouse. Once the models are defined, we need to instantiate them using the `dbt run` subcommand. This command will take the source SQL code you've written, translate it as necessary for your deployment target (aka, profile), and actually execute the transformation process. \n",
    "When complete, you'll need to verify and test your data and, if necessary, troubleshoot any issues. Finally, this process is repeated as necessary, typically going back to the model level when a new data source is required.\n",
    "\n",
    "## 3. Verifying database connections\n",
    "One step often needed for working with dbt is verifying the connectivity to a database or data warehouse. dbt includes the subcommand dbt debug, which is designed to check the connections to your defined databases or warehouses. Note that the data warehouse must be created and accessible first, or you will see failures in the output. When using DuckDB and dbt, this may require executing dbt run prior to use. We'll mention this for any exercise that requires it in this course.\n",
    "\n",
    "## 4. dbt run\n",
    "As noted previously, dbt run is the subcommand that actually performs the data transformations and pushes updates to the warehouse. It should be run whenever there are model changes, or when the data process needs to be materialized. Make sure to analyze the output of the dbt run command - it provides many details on the success or failures of each step in the dbt process. Please note that in this circumstance, materialized has a specific meaning in dbt. It means to execute the transformations on the source data and place the results into tables or views.\n",
    "\n",
    "```sql\n",
    "-- Modify the following line to change the materialization type\n",
    "with source_data as (\n",
    "    -- Add the query as described to generate the data model\n",
    "    select * from read_parquet('yellow_tripdata_2023-01-partial.parquet')\n",
    ")\n",
    "\n",
    "select * from source_data\n",
    "```\n",
    "\n",
    "```bash\n",
    "#!/usr/bin/env python3\n",
    "import duckdb\n",
    "con = duckdb.connect('dbt.duckdb', read_only=True)\n",
    "print(con.sql('select * from taxi_rides_raw limit 10'))\n",
    "print(con.sql('select count(*) as total_rides from taxi_rides_raw'))\n",
    "if (con.execute('select count(*) as total_rides from taxi_rides_raw').fetchall()[0][0] == 300000):\n",
    "  with open('/home/repl/workspace/successful_data_check', 'w') as f:\n",
    "    f.write('300000')\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "## 5. Table vs View\n",
    "One thing to remember is the difference between tables and views within a database or data warehouse. There's a lot of technical implementation details, but in general a table is an object within a database or warehouse that actually holds data. These objects take up space within the database, relative to the size of data inserted into the database. The content of a table is only updated when a specific command changes said data. Views, act like a table and are queryable as such, but they actually hold no information. As such, they take up very little space within the database itself. A view is usually defined as a select query against another table or tables. As such, the content in the response is generated with each query. We don't cover the implementation details here, but are introducing them as dbt can create tables or views within a database depending on the configurations you define. The actual implementation details for tables and views will be dependent on the database in question.\n",
    "\n",
    "```sql\n",
    "-- Modify the following line to change the materialization type\n",
    "{{ config(materialized='table')}}\n",
    "\n",
    "\n",
    "with source_data as (\n",
    "    select * from read_parquet('yellow_tripdata_2023-01-partial.parquet')\n",
    ")\n",
    "\n",
    "select * from source_data\n",
    "\n",
    "```\n",
    "\n",
    "## 6. Let's practice!\n",
    "We've covered a lot of information about the basics of using dbt for a first project. Let's practice some of these ideas in the exercises ahead. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. What is a dbt model?\n",
    "Let's take the next few minutes to discuss the idea of a dbt model, what it is, and how it's used within dbt.\n",
    "\n",
    "## 2. What is a data model?\n",
    "Before we get into how dbt defines and uses models, let's discuss the general definition of a data model. A data model is a conceptual idea with different definitions depending on the context it's used. In general, a data model represents the logical meaning behind a set of data, whether a database table, Dataframe, data structure, or so forth. This could be a group of orders, customers, or something like the details of earthquakes in a given region. The data model also represents how a set of data and its various components relate to each other. An example here could be various features of an animal, such as the number of legs, does it fly, etc, and how that information is maintained within the dataset. One of the primary purposes behind a data model is to help users collaborate and understand the data in a common way. In our example, we've created a list of species of animals, the number of legs, and if the animal is venomous. While a very simple model, this creates an agreed upon list of features that we use when discussing an animal. This provides for the collaboration between users / programs / and so forth as we have a defined set of attributes for communicating about the animal. Obviously we could use a different set of attributes to define our model of an animal. The selection of these attributes can define the effectiveness of the model. You should recognize that there are always trade-offs made when defining a model, including complexity, amount of space required, etc.\n",
    "\n",
    "## 3. What is a model in dbt?\n",
    "A model in dbt represents something more specific than a basic data model - it represents the various transformations performed on the raw source datasets. These transformations are typically written in SQL, though newer versions of dbt can use Python for models / transformations. Note that we won't be covering Python models in this course. Each model, or transformation, is usually a SELECT query, transforming the source data as desired. These queries are then saved in a text file, with a .sql extension. dbt will automatically use these files when tasked with various operations, such as dbt run.\n",
    "\n",
    "## 4. Simple dbt model\n",
    "Let's discuss for a moment the basics of creating a model in dbt. The first step is to create a directory under the models directory in your dbt project. This directory can be named anything, but may be referenced later, so it's best to keep it consistent. Next, a dot sql file is created as a text file. This can be done at the command line with a tool like touch, or via a text editor. The most important part is to create and add the appropriate SQL statement to the text file. In this case, we select the first_name and last_name columns from a table named source_table. Finally, we must execute the `dbt run` command to create, or rather materialize, the model.\n",
    "\n",
    "## 5. Reading from Parquet\n",
    "A quick aside before moving on, we need to mention the Parquet format. Parquet is a columnar, binary file format used by many tools to efficiently store data. It is becoming widespread for the purposes of sharing and distributing datasets. If you're not familiar with the term, in this case, columnar is in contrast to row-based, like Avro or typical relational database formats. Some of the common tools that work with Parquet are Apache Spark, Apache Arrow, and DuckDB. DuckDB is able to read Parquet files directly, without the need to import the data first. This can be done using the read_parquet function in a SQL query. An example query could be SELECT * FROM read_parquet open parenthesis single quote filename dot parquet end quote close parenthesis. You can also skip using the read_parquet if desired and reference the Parquet file using it directly in single quotes.\n",
    "\n",
    "## 6. Let's practice!\n",
    "There's a lot to learn about models in dbt, but first let's practice what we've covered so far in the exercises ahead. We'll cover more in the next lesson. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Updating dbt models\n",
    "Welcome back! Our next topic is the idea of updating models in dbt, whether those are ones we've created directly, or those created by colleagues.\n",
    "\n",
    "\n",
    "```bash\n",
    "-- Update with SQL to return requested information\n",
    "select \n",
    "  date_part('day', tpep_pickup_datetime) as day,\n",
    "  count(*) as total_riders\n",
    "from taxi_rides_raw\n",
    "where Payment_type = 1\n",
    "group by day\n",
    "```\n",
    "\n",
    "## 2. Why update?\n",
    "An advantage of working with dbt is to easily make changes to your project or your team's project without requiring you to start from scratch. Let's take a moment to review some reasons why you'd want to update your models: It could be an iterative task, where the requirements for your project have changed or have not been fully implemented yet. A common scenario is fixing bugs in the queries that define the models. Given that SQL can be considered a programming language of its own, there are likely to be issues that need to be fixed. Migrating the data, be it source or destination locations, can also require an update to your project.\n",
    "\n",
    "    1 Photo by Caspar Camille Rubin on Unsplash\n",
    "\n",
    "## 3. Update workflow\n",
    "As we've discussed why you'd need to update your models, let's look at a potential workflow to use when updating a dbt project. The first step is to check out a dbt project from your source control system, such as git. An example would be git clone dbt_project, then opening the dbt_project folder. You don't have to use git with dbt, but it is one of the advantages of doing, so as you can easily track changes / updates / modifications. Once you have the current project source, you'll want to find the appropriate model file in question and then update the query contents. This could be updating the query directly, creating a subquery, or otherwise modifying the .sql file contents. After updating the model or models, you'll need to apply these changes to the project. This can usually be done by simply running dbt run. Occasionally, larger changes need a full refresh of the model, which can be done by adding dash f to the dbt run command. If you see an error in your update or the results don't appear as expected, you might want to add the full refresh option and try again. Note that depending on your data and models, it might take a bit longer to run than a simple update. Finally, if any updates have been made and verified to work, you'll want to check the changes back into source control to keep the process easy in the future.\n",
    "\n",
    "## 4. YAML files\n",
    "In addition to directly updating .sql files for dbt models, you may also need to make changes in some YAML / .yml files. Typically these updates would be in one of two types of files, either the dbt_project.yml file or in a model_properties.yml file.\n",
    "\n",
    "## 5. dbt_project.yml\n",
    "The dbt_project.yml file contains settings that relate to the full project. This can include things such as the project name and version, as well as directory locations. The materialization settings for a model can also reside here, though settings in this file are applied globally. These include defined whether models are created as tables / views / etc in the data warehouse. Note that there is one dbt_project.yml file per project.\n",
    "\n",
    "## 6. model_properties.yml\n",
    "The model_properties.yml file is specific to settings and details for model information. This can include description, documentation details, and much more. We'll cover some more of this later in the course, but refer to the dbt documentation for more information. One interesting note is the file can actually be named anything as long as it exists somewhere in the models/ subdirectory and ends in a .yml extension. You can also have as many of these .yml files as needed.\n",
    "\n",
    "## 7. Let's practice!\n",
    "We've learned about updating our project and models. Let's practice these details in the coming exercises. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Hierarchical models in dbt\n",
    "Welcome back to our next topic! We've covered the basics of working with and updating models. Let's now take a look at hierarchical models and the components that go with them.\n",
    "\n",
    "## 2. What is a hierarchy in dbt?\n",
    "Our first question is, what is a hierarchy in dbt? A hierarchy represents the dependencies between models, meaning the relationship between source and transformed data. This is also known as a DAG, or a directed acyclic graph. It's sometimes known as a lineage graph. Note that while a DAG is a common concept in data engineering tools, such as Spark, Airflow, and so forth, we're referring to a DAG specifically as implemented in dbt. The primary purpose of a DAG or hierarchy is it allows models to be built and updated with their dependencies in mind. This forces dbt to determine the order that models must be built and run accordingly. If you look at the simple lineage graph to our right, the avg_fare_per_day and total_creditcard_riders_per_day tables depend on the taxi_rides_raw table. dbt will build the taxi_rides_raw table first, to make certain the data is available to build the other downstream tables. It should be noted that without the lineage graph, the tables would be built in alphabetical order, which would fail when attempting to build the avg_fare_per_day model as taxi_rides_raw would not yet be built.\n",
    "\n",
    "## 3. How are hierarchies defined?\n",
    "The next question is how are hierarchies defined in dbt? We can use the Jinja template language to define the model dependencies. This is done within the model definition file, meaning the .sql file. We'll discuss more about Jinja shortly. Most often, we'll define the hierarchies using the ref function within a Jinja template. To actually define a dependency, we simply replace the table name in our query with two opening curly braces, then ref open parenthesis single quote model name end quote close parenthesis, followed by two closing braces in our SQL query. The next step is to use dbt run, which will materialize the models. dbt will replace the ref templates with the actual table names in the generated SQL file A quick example illustrates the change - in the first query, we're directly using the name of the table. While this works, we may run into issues if the table is not created yet. To add the dependency, you'll notice we change the table name from taxi_rides_raw to {{ ref('taxi_rides_raw') }}.\n",
    "\n",
    "## 4. Jinja templating language\n",
    "We're not going to discuss it in depth, but I wanted to mention Jinja. If you're not familiar with it, Jinja is a simple text-based templating system used in many tools beyond just dbt, such as Django and Flask. Another way to consider the meaning of a template is simply one of substitution. To define a Jinja template, simply put the desired content between two opening and closing curly braces within your text files. When dbt is run, it will replace the contents of the braces with the correct result. The dbt tool has many Jinja functions available for use in projects. This allows for more dynamic usage of dbt, such as with different source and destination data locations. Some of the many Jinja functions in dbt include ref, which you've already seen. The config command is an easy way to access config settings, and the docs command allows access to various documentation content. There are, of course, many other Jinja templates made available for this project. We'll cover some more of these later in the course.\n",
    "\n",
    "```sql\n",
    "-- Update SQL to use Jinja reference\n",
    "select \n",
    "   date_part('day', tpep_pickup_datetime) as day,\n",
    "   count(*) as total_riders\n",
    "from {{ ref('taxi_rides_raw') }} --jinja template\n",
    "where payment_type = 1\n",
    "group by day\n",
    "```\n",
    "\n",
    "```bash\n",
    "repl:~/workspace/nyc_yellow_taxi$ dbt run -f\n",
    "00:39:49  Running with dbt=1.5.1\n",
    "00:39:49  Found 2 models, 0 tests, 0 snapshots, 0 analyses, 313 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics, 0 groups\n",
    "00:39:49  \n",
    "00:39:49  Concurrency: 1 threads (target='dev')\n",
    "00:39:49  \n",
    "00:39:49  1 of 2 START sql view model main.taxi_rides_raw ................................ [RUN]\n",
    "00:39:49  1 of 2 OK created sql view model main.taxi_rides_raw ........................... [OK in 0.14s]\n",
    "00:39:49  2 of 2 START sql view model main.creditcard_riders_by_day ...................... [RUN]\n",
    "00:39:49  2 of 2 OK created sql view model main.creditcard_riders_by_day ................. [OK in 0.05s]\n",
    "00:39:50  \n",
    "00:39:50  Finished running 2 view models in 0 hours 0 minutes and 0.29 seconds (0.29s).\n",
    "00:39:50  \n",
    "00:39:50  Completed successfully\n",
    "00:39:50  \n",
    "00:39:50  Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2\n",
    "repl:~/workspace/nyc_yellow_taxi$ \n",
    "```\n",
    "\n",
    "\n",
    "## 5. Let's practice!\n",
    "We've covered a lot in this video - let's practice our new skills in the exercises ahead! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Model troubleshooting\n",
    "Great job on those last exercises! Now let's spend some time with the techniques you'll use to troubleshoot common issues while working with models in dbt.\n",
    "\n",
    "## 2. Common model issues\n",
    "dbt encompasses several data technologies - as such, there are several areas that can cause trouble. Let's look at some common problems you may see when creating models in dbt. A widespread issue is errors in your queries that create the model. These can include syntax errors (a misspelled keyword or column) or logic errors (the SQL isn't doing what you initially expected.) Models in dbt are typically written in SQL, so any problem with your SQL code can appear here. Another common problem is invalid object references. This could be as simple as misspelling the table name, but it could also indicate trickier issues. Depending on how you reference your objects, you may see them named differently than you expect, causing errors. Let's look at each of these more closely.\n",
    "\n",
    "## 3. Query errors\n",
    "As is common to anyone writing SQL queries, you may have to rewrite portions of your queries for many reasons. These include syntax-related issues such as misspellings, incorrectly ordering the query, or missing some necessary components. Another common problem is using non-standard SQL commands with a database that doesn't support it. This could include using TOP instead of LIMIT, custom functions, and so on. These queries may work with one dbt backend, but not with another. Lastly, common SQL logic issues can show up when creating dbt models. This includes forgetting to group by all non-aggregated columns as well as incorrectly formatting / referencing CTEs.\n",
    "\n",
    "## 4. Invalid references\n",
    "Another issue with writing dbt models is using an invalid reference. With dbt's different backends, the tables and views that are created can be referenced in different ways. The default method is to query the tables simply as named, but a different backend may use something different. For example, using Google's BigQuery looks for a context name first, while Databricks will often reference tables with a preceding underscore. A typical problem is trying to reference objects in your queries that have not yet been generated. dbt does its best to order the object creations based on the order of use, but sometimes there are circular references that keep this from happening.\n",
    "\n",
    "## 5. Troubleshooting methods\n",
    "There are several methods to determine exactly where problems in your dbt models may exist. The first is using `dbt run` to try generating and creating the dbt objects. If there are errors in creating the models, you'll receive an error message and a suggestion of what to do, if available. The next area to investigate are the dbt logs. The generic logs can be found in the logs directory under dbt.log. There is also a log file for each job called `run_results.json`. This log file contains various information about the tasks and can point out errors found during the run. While `dbt run` helps find many issues, sometimes the problem is more subtle. Another trick is manually reviewing the SQL output of the generated model. The problem may be apparent upon review, but you can also copy the generated code into a SQL editor (ideally with access to the data objects) and verify it works as you expect. Finally, make sure to verify your fixes work and don't cause other issues before continuing.\n",
    "\n",
    "## 6. Let's practice!\n",
    "We've looked at several potential issues you may see while creating dbt models. Let's practice identifying and resolving these in the exercises ahead. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Order and process for troubleshooting model  \n",
    "\n",
    "1 - dbt run  \n",
    "2 - Review logs/dbt.log or run_results.json  \n",
    "3 - View generated SQL  \n",
    "4 - Running generated SQL manually  \n",
    "5 - Verify fix  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction to testing in dbt\n",
    "Welcome back! In this chapter, we're going to discuss testing in dbt and what that entails. Let's get started!\n",
    "\n",
    "## 2. What is a test?\n",
    "The first question you may be wondering is what is a test? In dbt, a test is an assertion or a validation of various dbt objects. \n",
    "This can include models, which we've covered thus far. It can also apply to other dbt objects such as sources, seeds, and snapshots. \n",
    "\n",
    "Primarily, tests are used to verify our data is as expected. \n",
    "This can include tests for null values, verifying the values are in range, or the relationships between data. \n",
    "\n",
    "We can also create custom tests for validating specific logic. We'll cover these in later videos.\n",
    "\n",
    "## 3. Test types\n",
    "There are three kinds of tests in dbt. The first is built-in, which are 4 pre-defined tests available for use. We'll cover these further in a moment. The other two types are singular and generic. We'll cover those in later videos.\n",
    "\n",
    "## 4. Built-in tests\n",
    "As mentioned, dbt has 4 built-in tests. The are as follows: Unique, which verifies all values in a column are unique. not_null, which verifies all values in a column are not null. accepted_values verifies all values are within a specific list. \n",
    "\n",
    "These values are listed in a values: option. relationships, which also takes a to: and field: option. It verifies connection of an object to a specific table or column.\n",
    "\n",
    "## 5. Where to apply tests?\n",
    "Model tests are defined in a YAML file within the models directory - other tests, like seed tests are defined in their respective directories. We will name this file model_properties.yml. This file can technically be named anything .yml, such as schema.yml. The naming depends on your preferences or requirements. The actual tests are defined under the tests subheading, under the column name option within the YAML. An example is the easiest way to see the content - here we're defining tests on two columns of the taxi_rides_raw model. The tpep_pickup_datetime has a not_null test defined. The payment_type column has a not_null test and an accepted values test applied. In this case, we're verifying that the values are between 1 and 6. You can apply as many tests as desired for each model within your project.\n",
    "\n",
    "## 6. Running tests\n",
    "To actually execute the tests in dbt, we go back to the venerable dbt command, and use the test subcommand, or simply dbt test. This defaults to running tests for our entire project. If we'd like to run it against a specific model, we can use the --select modelname option, such as dbt test --select customers to just run tests for a customer model. The output of the command will indicate whether the tests pass or fail, and which ones. It should be noted that to actually find where a test fails, we need to do a few more steps.\n",
    "\n",
    "model_properties.yml\n",
    "```yml\n",
    "version: 2\n",
    "\n",
    "models:\n",
    "- name: taxi_rides_raw\n",
    "  columns:\n",
    "    - name: fare_amount\n",
    "      tests:\n",
    "        - not_null\n",
    "    - name: payment_type\n",
    "      test:\n",
    "        - not_null\n",
    "        - accepted_values:\n",
    "            values: [1, 2, 3, 4, 5, 6]\n",
    "```\n",
    "\n",
    "\n",
    "```bash\n",
    "repl:~/workspace/nyc_yellow_taxi$ dbt run\n",
    "16:42:47  Running with dbt=1.5.1\n",
    "16:42:47  [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.\n",
    "There are 1 unused configuration paths:\n",
    "- models.nyc_yellow_taxi\n",
    "16:42:47  Found 1 model, 1 test, 0 snapshots, 0 analyses, 313 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics, 0 groups\n",
    "16:42:47  \n",
    "16:42:47  Concurrency: 1 threads (target='dev')\n",
    "16:42:47  \n",
    "16:42:47  1 of 1 START sql view model main.taxi_rides_raw ................................ [RUN]\n",
    "16:42:47  1 of 1 OK created sql view model main.taxi_rides_raw ........................... [OK in 0.11s]\n",
    "16:42:47  \n",
    "16:42:47  Finished running 1 view model in 0 hours 0 minutes and 0.20 seconds (0.20s).\n",
    "16:42:47  \n",
    "16:42:47  Completed successfully\n",
    "16:42:47  \n",
    "16:42:47  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1\n",
    "\n",
    "\n",
    "repl:~/workspace/nyc_yellow_taxi$ dbt test\n",
    "16:42:52  Running with dbt=1.5.1\n",
    "16:42:52  [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.\n",
    "There are 1 unused configuration paths:\n",
    "- models.nyc_yellow_taxi\n",
    "16:42:52  Found 1 model, 1 test, 0 snapshots, 0 analyses, 313 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics, 0 groups\n",
    "16:42:52  \n",
    "16:42:52  Concurrency: 1 threads (target='dev')\n",
    "16:42:52  \n",
    "16:42:52  1 of 1 START test not_null_taxi_rides_raw_fare_amount .......................... [RUN]\n",
    "16:42:52  1 of 1 PASS not_null_taxi_rides_raw_fare_amount ................................ [PASS in 0.08s]\n",
    "16:42:52  \n",
    "16:42:52  Finished running 1 test in 0 hours 0 minutes and 0.15 seconds (0.15s).\n",
    "16:42:52  \n",
    "16:42:52  Completed successfully\n",
    "16:42:52  \n",
    "16:42:52  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1\n",
    "repl:~/workspace/nyc_yellow_taxi$ \n",
    "```\n",
    "\n",
    "## 7. Finding failures\n",
    "To find the specific issues in our data, we need to first look at the compiled SQL code. This normally resides in the `target/compiled/projectname/models/model_properties.yml` directory. \n",
    "\n",
    "In our case, it will be the `target/compiled/nyc_yellow_taxi/models/model_properties.yml/` directory. Look for the appropriate .sql file that matches the failed test or tests. Copy those contents into your database client and check how many rows exist with the issue. You can then remove the data manually from source or modify your model scripts to handle the issue. It's typically easier to do the second to handle future issues. Once complete, you'll want to rerun dbt run and dbt test to verify the issue is fixed.\n",
    "\n",
    "## 8. Let's practice!\n",
    "We've covered a lot about testing in this video - let's practice what we've learned in the exercises ahead. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "repl:~/workspace/nyc_yellow_taxi$ dbt test\n",
    "16:50:23  Running with dbt=1.5.1\n",
    "16:50:23  [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.\n",
    "There are 1 unused configuration paths:\n",
    "- models.nyc_yellow_taxi\n",
    "16:50:23  Found 1 model, 3 tests, 0 snapshots, 0 analyses, 313 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics, 0 groups\n",
    "16:50:23  \n",
    "16:50:23  Concurrency: 1 threads (target='dev')\n",
    "16:50:23  \n",
    "16:50:23  1 of 3 START test accepted_values_taxi_rides_raw_payment_type__1__2__3__4__5__6  [RUN]\n",
    "16:50:23  1 of 3 FAIL 1 accepted_values_taxi_rides_raw_payment_type__1__2__3__4__5__6 .... [FAIL 1 in 0.06s]  <-- there 0 value\n",
    "16:50:23  2 of 3 START test not_null_taxi_rides_raw_fare_amount .......................... [RUN]\n",
    "16:50:23  2 of 3 PASS not_null_taxi_rides_raw_fare_amount ................................ [PASS in 0.03s]\n",
    "16:50:23  3 of 3 START test not_null_taxi_rides_raw_payment_type ......................... [RUN]\n",
    "16:50:24  3 of 3 PASS not_null_taxi_rides_raw_payment_type ............................... [PASS in 0.03s]\n",
    "16:50:24  \n",
    "16:50:24  Finished running 3 tests in 0 hours 0 minutes and 0.20 seconds (0.20s).\n",
    "16:50:24  \n",
    "16:50:24  Completed with 1 error and 0 warnings:\n",
    "16:50:24  \n",
    "16:50:24  Failure in test accepted_values_taxi_rides_raw_payment_type__1__2__3__4__5__6 (models/taxi_rides/model_properties.yml)\n",
    "16:50:24    Got 1 result, configured to fail if != 0\n",
    "16:50:24  \n",
    "16:50:24    compiled Code at target/compiled/taxi_project/models/taxi_rides/model_properties.yml/accepted_values_taxi_rides_raw_payment_type__1__2__3__4__5__6.sql\n",
    "16:50:24  \n",
    "16:50:24  Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 1. Creating singular tests\n",
    "Nice work on the previous exercises! Now let's take a look at the first kind of custom tests available in dbt - singular data tests.\n",
    "\n",
    "## 2. What is a singular test?\n",
    "So what is a singular test? It is the simplest form of a custom data test within dbt. It is written as a SQL query, which must return the failing rows. Singular tests are defined as .sql files within the appropriate tests directory for the type of object being tested.\n",
    "\n",
    "## 3. Example singular test\n",
    "Let's take a look at an example singular test. Let's say we have a simplified order table, with 7 columns. \n",
    "\n",
    "Two of those columns are the subtotal and order_total. \n",
    "We want to create a test to verify that the order_total is greater than or equal to the subtotal. \n",
    "\n",
    "We're essentially trying to verify that all taxes / shipping / etc have been applied appropriately. We'll create a query of select * from order where order_total < subtotal This may seem a little strange as this is the opposite of what we're wanting to validate. \n",
    "\n",
    "`Remember that when writing dbt singular tests, we want to return the rows that specifically fail our test condition.` \n",
    "\n",
    "In this case, we're trying to verify that all rows have an order_total greater than or equal to the subtotal. As such, we write our query looking for any rows where the order_total is less than the subtotal, indicating a problem row. By convention, we'll name this file assert_order_total_gte_subtotal.sql and place it in the tests directory. Note that we could name this file whatever we wish, but it's helpful to be descriptive in the name. The test name will be referenced in any errors / logs of the project, so it helps in debugging to know exactly what failed.\n",
    "\n",
    "## 4. Singular test with Jinja\n",
    "Let's look at another quick example, this time using Jinja templates. Much like when we define models, we can use Jinja functions to simplify the creation of the test. The most common function we'll use is the one you're already familiar with, the ref function. As a reminder, this handles substituting the proper name of an object when it's compiled for our target data warehouse. In this case, the ref('order') function would return the proper table name for order within the test. There are other functions that can be used, such as the source function. We'll talk about these further in later videos. Finally, it should be noted that dbt performs the substitutions when the test is run. As such, if your dbt profile changes, you need to run your project again before testing.\n",
    "\n",
    "\n",
    "```sql\n",
    "select *\n",
    "from {{ ref('order) }}\n",
    "where order_total < subtotal\n",
    "```\n",
    "\n",
    "\n",
    "## 5. Test debugging\n",
    "One last topic before we move to exercises - let's discuss test debugging. The workflow for tests is similar to developing models, but is less involved. When creating a new test, it's often best to use a SQL editor to create the initial query and work through any typical SQL issues there. Place the query into the appropriate file, making sure to name the test uniquely. If you don't, dbt can still use it but it will be difficult to determine which version of a test passes or fails in the output. To speed development, you can use the dbt test --select testname command to run only that specific test. When you get a large dataset and have many tests, the amount of time required to run them all can increase greatly. The --select option should cut this down noticeably. Finally, check any errors in your test and update accordingly.\n",
    "\n",
    "\n",
    "```bash\n",
    "dbt test --select <testname>\n",
    "```\n",
    "## 6. Let's practice!\n",
    "We've discussed a lot about singular tests in dbt - let's implement what we've learned in the exercises ahead. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice\n",
    "\n",
    "Place each item in the order it should happen, from first to last.\n",
    "\n",
    "1 - Determine the validation required\n",
    "\n",
    "2 - Create SQL query\n",
    "\n",
    "3 - Save the Query in a test .sql file\n",
    "\n",
    "4 - dbt run\n",
    "\n",
    "5 - dbt test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice \n",
    "I have add the condition in the test to select where there is 0\n",
    "\n",
    "```sql\n",
    "select * \n",
    "from taxi_rides_raw\n",
    "-- Complete the test on the following line\n",
    "WHERE tpep_dropoff_datetime - tpep_pickup_datetime = 0\n",
    "\n",
    "-- other solution valid\n",
    "#WHERE tpep_pickup_datetime = tpep_dropoff_datetime\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "dbt run\n",
    "20:39:03  Running with dbt=1.5.1\n",
    "20:39:03  [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.\n",
    "There are 1 unused configuration paths:\n",
    "- models.nyc_yellow_taxi\n",
    "20:39:03  Found 1 model, 4 tests, 0 snapshots, 0 analyses, 313 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics, 0 groups\n",
    "20:39:03  \n",
    "20:39:03  Concurrency: 1 threads (target='dev')\n",
    "20:39:03  \n",
    "20:39:03  1 of 1 START sql view model main.taxi_rides_raw ................................ [RUN]\n",
    "20:39:03  1 of 1 OK created sql view model main.taxi_rides_raw ........................... [OK in 0.13s]\n",
    "20:39:03  \n",
    "20:39:03  Finished running 1 view model in 0 hours 0 minutes and 0.22 seconds (0.22s).\n",
    "20:39:03  \n",
    "20:39:03  Completed successfully\n",
    "20:39:03  \n",
    "20:39:03  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1\n",
    "\n",
    "\n",
    "## BEFORE\n",
    "\n",
    "repl:~/workspace/nyc_yellow_taxi$ dbt test\n",
    "20:37:18  Running with dbt=1.5.1\n",
    "20:37:18  [WARNING]: Configuration paths exist in your dbt_project.yml file whi\n",
    "ch do not apply to any resources.\n",
    "There are 1 unused configuration paths:\n",
    "- models.nyc_yellow_taxi\n",
    "20:37:18  Found 1 model, 4 tests, 0 snapshots, 0 analyses, 313 macros, 0 operat\n",
    "ions, 0 seed files, 0 sources, 0 exposures, 0 metrics, 0 groups\n",
    "20:37:18  \n",
    "20:37:18  Concurrency: 1 threads (target='dev')\n",
    "20:37:18  \n",
    "20:37:18  1 of 4 START test accepted_values_taxi_rides_raw_payment_type__1__2__\n",
    "3__4__5__6  [RUN]\n",
    "20:37:18  1 of 4 PASS accepted_values_taxi_rides_raw_payment_type__1__2__3__4__\n",
    "5__6 ...... [PASS in 0.13s]\n",
    "20:37:18  2 of 4 START test assert_trip_duration_gt_0 .................................... [RUN]\n",
    "20:37:18  2 of 4 FAIL 300000 assert_trip_duration_gt_0 ................................... [FAIL 300000 in 0.03s]\n",
    "20:37:18  3 of 4 START test not_null_taxi_rides_raw_fare_amount .......................... [RUN]\n",
    "20:37:18  3 of 4 PASS not_null_taxi_rides_raw_fare_amount ................................ [PASS in 0.03s]\n",
    "20:37:18  4 of 4 START test not_null_taxi_rides_raw_payment_type ......................... [RUN]\n",
    "20:37:18  4 of 4 PASS not_null_taxi_rides_raw_payment_type ............................... [PASS in 0.03s]\n",
    "20:37:18  \n",
    "20:37:18  Finished running 4 tests in 0 hours 0 minutes and 0.32 seconds (0.32s).\n",
    "20:37:18  \n",
    "20:37:18  Completed with 1 error and 0 warnings:\n",
    "20:37:18  \n",
    "20:37:18  Failure in test assert_trip_duration_gt_0 (tests/assert_trip_duration_gt_0.sql)\n",
    "20:37:18    Got 300000 results, configured to fail if != 0\n",
    "20:37:18  \n",
    "20:37:18    compiled Code at target/compiled/taxi_project/tests/assert_trip_duration_gt_0.sql\n",
    "20:37:18  \n",
    "20:37:18  Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## AFTER\n",
    "\n",
    "repl:~/workspace/nyc_yellow_taxi$ dbt test\n",
    "20:39:13  Running with dbt=1.5.1\n",
    "20:39:13  [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.\n",
    "There are 1 unused configuration paths:\n",
    "- models.nyc_yellow_taxi\n",
    "20:39:13  Found 1 model, 4 tests, 0 snapshots, 0 analyses, 313 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics, 0 groups\n",
    "20:39:13  \n",
    "20:39:13  Concurrency: 1 threads (target='dev')\n",
    "20:39:13  \n",
    "20:39:13  1 of 4 START test accepted_values_taxi_rides_raw_payment_type__1__2__3__4__5__6  [RUN]\n",
    "20:39:13  1 of 4 PASS accepted_values_taxi_rides_raw_payment_type__1__2__3__4__5__6 ...... [PASS in 0.11s]\n",
    "20:39:13  2 of 4 START test assert_trip_duration_gt_0 .................................... [RUN] <----working>\n",
    "20:39:13  2 of 4 PASS assert_trip_duration_gt_0 .......................................... [PASS in 0.02s]\n",
    "20:39:13  3 of 4 START test not_null_taxi_rides_raw_fare_amount .......................... [RUN]\n",
    "20:39:13  3 of 4 PASS not_null_taxi_rides_raw_fare_amount ................................ [PASS in 0.03s]\n",
    "20:39:13  4 of 4 START test not_null_taxi_rides_raw_payment_type ......................... [RUN]\n",
    "20:39:13  4 of 4 PASS not_null_taxi_rides_raw_payment_type ............................... [PASS in 0.03s]\n",
    "20:39:13  \n",
    "20:39:13  Finished running 4 tests in 0 hours 0 minutes and 0.28 seconds (0.28s).\n",
    "20:39:13  \n",
    "20:39:13  Completed successfully\n",
    "20:39:13  \n",
    "20:39:13  Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4\n",
    "repl:~/workspace/nyc_yellow_taxi$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# . Creating custom reusable tests\n",
    "Welcome back! Let's now take a look at the most powerful kind of test available to us - the generic, or reusable, test.\n",
    "\n",
    "## 2. What is a reusable test?\n",
    "A reusable test, also called a generic test in dbt terminology, is a test that can be reused in multiple situations. \n",
    "\n",
    "It's much like a built-in dbt test, but can check on any condition you can query within SQL. A generic test is built using Jinja templating - we'll go over the details of that implementation in a moment. \n",
    "The file is then saved as a .sql file within the tests/generic subfolder in the dbt project. \n",
    "It should be noted that to use a reusable test, it must be defined for each model that uses it in the model_properties.yml file. Again, this is similar to how we use the built-in tests within dbt.\n",
    "\n",
    "\n",
    "## 3. Creating a reusable test\n",
    "To actually create a usable test, we need to add a few things to our .sql file. \n",
    "\n",
    "For most any generic test, we will be substituting in two objects - model and column_name. \n",
    "\n",
    "The are treated as arguments to a Jinja function that becomes our test name. The first line of our test file must contain at least \n",
    "`{% test testname(model, column_name) %}` I say at least, as it's possible to add further arguments, which we'll discuss in a moment. \n",
    "\n",
    "The next portion of the file contains our actual query, but note that we'll substitute in the model argument as a Jinja reference for the table, and the column_name argument as a reference for our validation check, usually in the where clause. \n",
    "\n",
    "Finally we'll add the line `{% endtest %}` to finish the code of the test.\n",
    "\n",
    "## 4. Reusable test example\n",
    "Here's a simple example of a reusable test to check if a column is greater than 0. First, we define the test as mentioned using `check_gt_0` as the function name, with model and column_name as parameters. Our query is a simple select * from table where object greater than 0. Note that we use the {{ model }} and {{ column_name }} substitutions. Finally, we add the footer as required and save the file in the tests/generic directory.\n",
    "\n",
    "## 5. Applying reusable test to model\n",
    "To apply our new reusable test, we update our model_properties.yml file as we did with the built-in tests. For each test we wish to apply, we add it to the model / column as necessary. The model name is the model argument in the test. The column name is the column_name argument in the test. You'll see we have a built-in test defined on the taxi_rides_raw table, verifying that the tpep_pickup_datetime is not null. Let's now add our check_gt_0 test to the total_fare column. The test will now be applied when we next use dbt test.\n",
    "\n",
    "```sql\n",
    "{% test check_gt_0(model,column_name) %}\n",
    "\n",
    "SELECT * \n",
    "from {{ model }}\n",
    "WHERE {{ column_name }} > 0\n",
    "\n",
    "{% endtest %}}\n",
    "```\n",
    "\n",
    "update model_properties.yml\n",
    "\n",
    "```yaml\n",
    "version: 2\n",
    "models:\n",
    "- name: taxi_rides_raw\n",
    "columns:\n",
    "- name: tpep_pickup_datetime\n",
    "tests:\n",
    "- not_null\n",
    "- name: total_fare\n",
    "tests:\n",
    "- check_gt_0\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "## 6. Extra parameters\n",
    "It is also possible to add extra parameters to our reusable tests. This is similar to how the accepted_values and relationships tests have extra entries in the model_properties.yml file. \n",
    "\n",
    "To add the extra arguments, we create the additional arguments on the Jinja header then substitute into our select query as required. You can theoretically add multiple extra parameters as needed, but it's suggested to keep the number of required parameters fairly short.\n",
    "\n",
    "```sql\n",
    "{% test check_columns_unequal(model, column_name, column_name2) %}\n",
    "select * from {{ model }}\n",
    "where {{ column_name }} = {{ column_name2 }}\n",
    "{% endtest %}\n",
    "```\n",
    "\n",
    "\n",
    "## 7. Applying extra parameters tests\n",
    "To apply tests with extra parameters, we first add the test as normal to the model_properties.yml file. We then add the extra arguments as options under the test name. In this case, we define the check_columns_unequal entry to use the column_name2 parameter. Note the spacing as this is significant in YAML.\n",
    "\n",
    "```yaml\n",
    "models:\n",
    "- name: order\n",
    "columns:\n",
    "- name: order_time\n",
    "tests:\n",
    "- check_columns_unequal:\n",
    "column_name2: shipped_time\n",
    "```\n",
    "\n",
    "## 8. Let's practice!\n",
    "We've covered a lot about generic tests - let's solidify our knowledge in the exercises ahead. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercice \n",
    "\n",
    "\n",
    "```sql\n",
    "{% test check_gt_0(model, column_name) %}\n",
    "select * \n",
    "from {{ model }}\n",
    "where {{ column_name }} <= 0\n",
    "{% endtest %}\n",
    "```\n",
    "\n",
    "properties\n",
    "\n",
    "```YAML\n",
    "version: 2\n",
    "\n",
    "# Replace any entry of ____ with the appropriate content\n",
    "models:\n",
    "- name: taxi_rides_raw\n",
    "  columns:\n",
    "    - name: fare_amount\n",
    "      tests:\n",
    "        - check_gt_0\n",
    "    - name: total_amount\n",
    "      tests:\n",
    "        - check_gt_0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice \n",
    "\n",
    "Updating from singular to reusable test\n",
    "\n",
    "As you've recently successfully implemented a reusable test, you decide to go back and see if you can update a previous singular test to be reusable. Looking in your project files, you note that you previously created the assert_trip_duration_gt_0 test, which specifically checked for two fields being equal (in this case tpep_pickup_datetime and tpep_dropoff_datetime). After viewing your implementation, you decide to try and create a reusable test that implements the same functionality.\n",
    "\n",
    "Note: Your previous implementation is available and open to you for reference.\n",
    "\n",
    "assert_trip_duration_gt_0.sql\n",
    "```sql\n",
    "select * \n",
    "from taxi_rides_raw\n",
    "where tpep_pickup_datetime = tpep_dropoff_datetime\n",
    "```\n",
    "\n",
    "model_properties.yml\n",
    "\n",
    "```yaml\n",
    "version: 2\n",
    "\n",
    "models:\n",
    "- name: taxi_rides_raw\n",
    "  columns:\n",
    "    - name: tpep_pickup_datetime\n",
    "      tests:\n",
    "        - columns_equal:\n",
    "            column_name2: tpep_dropoff_datetime\n",
    "\n",
    "```\n",
    "\n",
    "columns_equal.sql\n",
    "\n",
    "```sql\n",
    "{% test columns_equal(model, column_name, column_name2) %}\n",
    "select *\n",
    "from {{ model }}\n",
    "where {{ column_name }} = {{ column_name2}}\n",
    "{% endtest %}\n",
    "```\n",
    "\n",
    "\n",
    "```bash\n",
    "repl:~/workspace/nyc_yellow_taxi$ dbt run\n",
    "22:29:51  Running with dbt=1.5.1\n",
    "22:29:51  [WARNING]: Configuration paths exist in your dbt_project.yml file\n",
    " which do not apply to any resources.\n",
    "There are 1 unused configuration paths:\n",
    "- models.nyc_yellow_taxi\n",
    "22:29:51  Found 1 model, 2 tests, 0 snapshots, 0 analyses, 314 macros, 0 op\n",
    "erations, 0 seed files, 0 sources, 0 exposures, 0 metrics, 0 groups\n",
    "22:29:51  \n",
    "22:29:51  Concurrency: 1 threads (target='dev')\n",
    "22:29:51  \n",
    "22:29:51  1 of 1 START sql view model main.taxi_rides_raw .................\n",
    "............... [RUN]\n",
    "22:29:51  1 of 1 OK created sql view model main.taxi_rides_raw ............\n",
    "............... [OK in 0.16s]\n",
    "22:29:51  \n",
    "22:29:51  Finished running 1 view model in 0 hours 0 minutes and 0.26 secon\n",
    "ds (0.26s).\n",
    "22:29:51  \n",
    "22:29:51  Completed successfully\n",
    "22:29:51  \n",
    "22:29:51  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1\n",
    "```\n",
    "\n",
    "\n",
    "```bash\n",
    "repl:~/workspace/nyc_yellow_taxi$ dbt test --select taxi_rides_raw.sql\n",
    "22:32:45  Running with dbt=1.5.1\n",
    "22:32:45  [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.\n",
    "There are 1 unused configuration paths:\n",
    "- models.nyc_yellow_taxi\n",
    "22:32:45  Found 1 model, 2 tests, 0 snapshots, 0 analyses, 314 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics, 0 groups\n",
    "22:32:45  \n",
    "22:32:45  Concurrency: 1 threads (target='dev')\n",
    "22:32:45  \n",
    "22:32:45  1 of 1 START test columns_equal_taxi_rides_raw_tpep_pickup_datetime__tpep_dropoff_datetime  [RUN]\n",
    "22:32:46  1 of 1 FAIL 109 columns_equal_taxi_rides_raw_tpep_pickup_datetime__tpep_dropoff_datetime  [FAIL 109 in 0.09s]\n",
    "22:32:46  \n",
    "22:32:46  Finished running 1 test in 0 hours 0 minutes and 0.16 seconds (0.16s).\n",
    "22:32:46  \n",
    "22:32:46  Completed with 1 error and 0 warnings:\n",
    "22:32:46  \n",
    "22:32:46  Failure in test columns_equal_taxi_rides_raw_tpep_pickup_datetime__tpep_dropoff_datetime (models/taxi_rides/model_properties.yml)\n",
    "22:32:46    Got 109 results, configured to fail if != 0\n",
    "22:32:46  \n",
    "22:32:46    compiled Code at target/compiled/taxi_project/models/taxi_rides/model_properties.yml/columns_equal_taxi_rides_raw_8a4c18eecaabffcffe7e044ddfa588a6.sql\n",
    "22:32:46  \n",
    "22:32:46  Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Creating and generating dbt documentation\n",
    "Welcome back! Now that we've worked with tests in dbt, let's take a look at an often overlooked issue in data engineering and warehousing: documentation.\n",
    "\n",
    "## 2. Why document?\n",
    "It may sound like a silly question, but we should consider why we want to document a data project. It's common when working on a data project to create notes within the code and queries for ourself or any other engineers working at that level. Data projects, however have more consumers than just these roles and it's not feasible to provide everyone with access to source code just for documentation purposes. Centralizing the source of documentation is another benefit to documenting data projects. While it is possible to provide this information via something like email, it's far easier to have the documentation available at a known location. We're also interested in providing details about updates and changes to our data feeds, as well as creating a repository for examples, suggestions for the use of the data, and details about SLAs (Service Level Agreements - how often the data is updated and any guarantees of accessibility of the data.)\n",
    "\n",
    "## 3. Creating documentation in dbt\n",
    "dbt provides options to automatically add documentation to your project in various ways. This includes adding information to model definitions, including the overall model description as well as individual column descriptions if desired. The dbt documentation also can show the data lineage or DAG (directed acyclic graph), meaning the flow of data from initial source tables and any transformation or aggregate tables we create. We can also get any information about tests and data validations that are applied to our models from the dbt documentation tools. Finally, we can also see the details about the generated data warehouse - including the column data types and data sizes that are created when the data is processed.\n",
    "\n",
    "## 4. Generating documentation in dbt\n",
    "To actually generate the documentation, dbt provides a subcommand, dbt docs. The dbt docs subcommand has a few subcommands of its own. This includes the help option, dbt docs -h, which gives a description of the commands available for dbt docs. Let's talk about the primary one, dbt docs generate. This will traverse the content of our project, automatically creating the documentation website and formatting it into a static website. Given this documentation will update as we add models, tests, and so on, we should run this command after generating the project with dbt run.\n",
    "\n",
    "## 5. Accessing documentation\n",
    "To access the generated documentation, we'll need a web browser and the documentation to be hosted somewhere. There are several options for hosting the documentation depending on our needs. These can include using the other subcommand for dbt docs, the dbt docs serve subcommand. This starts a webserver on the local system and provides access to the documentation. Note that while convenient, this should only be used locally during development as it is not designed with security in mind. The other option for hosting the documentation is using another hosting service. This can include dbt cloud, Amazon's S3, any modern web server including Nginx, Apache, and so forth.\n",
    "\n",
    "## 6. Documentation example\n",
    "This is an example view of the documentation page, which can provide details of the models, description information, column details, and the lineage graphs.\n",
    "\n",
    "## 7. Let's practice!\n",
    "We've covered quite a bit about using documentation in dbt. Let's solidify what we've learned in the exercises ahead. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dbt docs -h\n",
    "  dbt docs generate\n",
    "  dbt doc serve\n",
    "\n",
    "\n",
    "should be run after dbt run\n",
    "\n",
    "```bash\n",
    "PS C:\\Users\\Steve\\Downloads\\dbt-duckdb> dbt docs -h\n",
    "Usage: dbt docs [OPTIONS] COMMAND [ARGS]...\n",
    "\n",
    "  Generate or serve the documentation website for your project\n",
    "\n",
    "Options:\n",
    "  --cache-selected-only / --no-cache-selected-only\n",
    "                                  At start of run, populate relational cache  \n",
    "                                  only for schemas containing selected nodes, \n",
    "                                  or for all schemas of interest.\n",
    "  -d, --debug / --no-debug        Display debug logging during dbt execution. \n",
    "                                  Useful for debugging and making bug reports.\n",
    "  --defer / --no-defer            If set, resolve unselected nodes by\n",
    "                                  deferring to the manifest within the --state\n",
    "                                  directory.\n",
    "  --defer-state DIRECTORY         Override the state directory for deferral   \n",
    "                                  only.\n",
    "  --deprecated-favor-state TEXT   Internal flag for deprecating old env var.  \n",
    "  -x, --fail-fast / --no-fail-fast\n",
    "                                  Stop execution on first failure.\n",
    "  --favor-state / --no-favor-state\n",
    "                                  If set, defer to the argument provided to   \n",
    "                                  the state flag for resolving unselected     \n",
    "                                  nodes, even if the node(s) exist as a       \n",
    "                                  database object in the current environment. \n",
    "  --indirect-selection [eager|cautious|buildable|empty]\n",
    "                                  Choose which tests to select that are       \n",
    "                                  adjacent to selected resources. Eager is    \n",
    "                                  most inclusive, cautious is most exclusive, \n",
    "                                  and buildable is in between. Empty includes \n",
    "                                  no tests at all.\n",
    "  --log-cache-events / --no-log-cache-events\n",
    "                                  Enable verbose logging for relational cache \n",
    "                                  events to help when debugging.\n",
    "  --log-format [text|debug|json|default]\n",
    "                                  Specify the format of logging to the console\n",
    "                                  and the log file. Use --log-format-file to\n",
    "                                  configure the format for the log file\n",
    "                                  differently than the console.\n",
    "  --log-format-file [text|debug|json|default]\n",
    "                                  Specify the format of logging to the log\n",
    "                                  file by overriding the default value and the\n",
    "                                  general --log-format setting.\n",
    "  --log-level [debug|info|warn|error|none]\n",
    "                                  Specify the minimum severity of events that\n",
    "                                  are logged to the console and the log file.\n",
    "                                  Use --log-level-file to configure the\n",
    "                                  severity for the log file differently than\n",
    "                                  the console.\n",
    "  --log-level-file [debug|info|warn|error|none]\n",
    "                                  Specify the minimum severity of events that\n",
    "                                  are logged to the log file by overriding the\n",
    "                                  default value and the general --log-level\n",
    "                                  setting.\n",
    "  --log-path PATH                 Configure the 'log-path'. Only applies this\n",
    "                                  setting for the current run. Overrides the\n",
    "                                  'DBT_LOG_PATH' if it is set.\n",
    "  --partial-parse / --no-partial-parse\n",
    "                                  Allow for partial parsing by looking for and\n",
    "                                  writing to a pickle file in the target\n",
    "                                  directory. This overrides the user\n",
    "                                  configuration file.\n",
    "  --populate-cache / --no-populate-cache\n",
    "                                  At start of run, use `show` or\n",
    "                                  `information_schema` queries to populate a\n",
    "                                  relational cache, which can speed up\n",
    "                                  subsequent materializations.\n",
    "  --print / --no-print            Output all {{ print() }} macro calls.\n",
    "  --printer-width INTEGER         Sets the width of terminal output\n",
    "  --profile TEXT                  Which existing profile to load. Overrides\n",
    "                                  setting in dbt_project.yml.\n",
    "  -q, --quiet / --no-quiet        Suppress all non-error logging to stdout.\n",
    "                                  Does not affect {{ print() }} macro calls.\n",
    "  -r, --record-timing-info PATH   When this option is passed, dbt will output\n",
    "                                  low-level timing stats to the specified\n",
    "                                  file. Example: `--record-timing-info\n",
    "                                  output.profile`\n",
    "  --send-anonymous-usage-stats / --no-send-anonymous-usage-stats\n",
    "                                  Send anonymous usage stats to dbt Labs.\n",
    "  --state DIRECTORY               Unless overridden, use this state directory\n",
    "                                  for both state comparison and deferral.\n",
    "  --static-parser / --no-static-parser\n",
    "                                  Use the static parser.\n",
    "  -t, --target TEXT               Which target to load for the given profile\n",
    "  --use-colors / --no-use-colors  Specify whether log output is colorized in\n",
    "                                  the console and the log file. Use --use-\n",
    "                                  colors-file/--no-use-colors-file to colorize\n",
    "                                  the log file differently than the console.\n",
    "  --use-colors-file / --no-use-colors-file\n",
    "                                  Specify whether log file output is colorized\n",
    "                                  by overriding the default value and the\n",
    "                                  general --use-colors/--no-use-colors\n",
    "                                  setting.\n",
    "  --use-experimental-parser / --no-use-experimental-parser\n",
    "                                  Enable experimental parsing features.\n",
    "  -V, -v, --version               Show version information and exit\n",
    "  --version-check / --no-version-check\n",
    "                                  If set, ensure the installed dbt version\n",
    "                                  matches the require-dbt-version specified in\n",
    "                                  the dbt_project.yml file (if any).\n",
    "                                  Otherwise, allow them to differ.\n",
    "  --warn-error                    If dbt would normally warn, instead raise an\n",
    "                                  exception. Examples include --select that\n",
    "                                  selects nothing, deprecations,\n",
    "                                  configurations with no associated models,\n",
    "                                  invalid test configurations, and missing\n",
    "                                  sources/refs in tests.\n",
    "  --warn-error-options WARNERROROPTIONSTYPE\n",
    "                                  If dbt would normally warn, instead raise an\n",
    "                                  exception based on include/exclude\n",
    "                                  configuration. Examples include --select\n",
    "                                  that selects nothing, deprecations,\n",
    "                                  configurations with no associated models,\n",
    "                                  invalid test configurations, and missing\n",
    "                                  sources/refs in tests. This argument should\n",
    "                                  be a YAML string, with keys 'include' or\n",
    "                                  'exclude'. eg. '{\"include\": \"all\",\n",
    "                                  \"exclude\": [\"NoNodesForSelectionCriteria\"]}'\n",
    "  --write-json / --no-write-json  Whether or not to write the manifest.json\n",
    "                                  and run_results.json files to the target\n",
    "                                  directory\n",
    "  -h, --help                      Show this message and exit.\n",
    "\n",
    "Commands:\n",
    "  generate  Generate the documentation website for your project\n",
    "  serve     Serve the documentation website for your project\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dbt docs generate and serve\n",
    "\n",
    "```bash\n",
    "PS C:\\Users\\Steve\\Downloads\\dbt-duckdb> dbt run\n",
    "00:26:36  Running with dbt=1.8.7\n",
    "00:26:36  Registered adapter: duckdb=1.8.4\n",
    "00:26:37  [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.\n",
    "There are 1 unused configuration paths:\n",
    "- models.nyc_yellow_taxi.example\n",
    "00:26:37  Found 408 macros\n",
    "00:26:37  \n",
    "00:26:37  Nothing to do. Try checking your model configs and model specification args\n",
    "\n",
    "PS C:\\Users\\Steve\\Downloads\\dbt-duckdb> dbt docs generate\n",
    "00:27:04  Running with dbt=1.8.7\n",
    "00:27:04  Registered adapter: duckdb=1.8.4\n",
    "00:27:04  [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.\n",
    "There are 1 unused configuration paths:\n",
    "- models.nyc_yellow_taxi.example\n",
    "00:27:05  Found 408 macros\n",
    "00:27:05  \n",
    "00:27:05  Nothing to do. Try checking your model configs and model specification args\n",
    "00:27:05  Building catalog\n",
    "00:27:07  Catalog written to C:\\Users\\Steve\\Downloads\\dbt-duckdb\\target\\catalog.json\n",
    "\n",
    "\n",
    "\n",
    "PS C:\\Users\\Steve\\Downloads\\dbt-duckdb> dbt doc serve\n",
    "Usage: dbt [OPTIONS] COMMAND [ARGS]...\n",
    "Try 'dbt -h' for help.\n",
    "\n",
    "Error: No such command 'doc'.\n",
    "PS C:\\Users\\Steve\\Downloads\\dbt-duckdb> dbt docs serve\n",
    "00:27:29  Running with dbt=1.8.7\n",
    "Serving docs at 8080\n",
    "To access from your browser, navigate to: http://localhost:8080\n",
    "\n",
    "\n",
    "\n",
    "Press Ctrl+C to exit.\n",
    "127.0.0.1 - - [05/Oct/2024 19:27:30] \"GET / HTTP/1.1\" 200 -\n",
    "127.0.0.1 - - [05/Oct/2024 19:27:31] code 404, message File not found\n",
    "127.0.0.1 - - [05/Oct/2024 19:27:31] \"GET /$%7Brequire('./assets/favicons/favicon.ico')%7D HTTP/1.1\" 404 -\n",
    "127.0.0.1 - - [05/Oct/2024 19:27:31] \"GET /manifest.json?cb=1728174451080 HTTP/1.1\" 200 -\n",
    "127.0.0.1 - - [05/Oct/2024 19:27:31] \"GET /catalog.json?cb=1728174451080 HTTP/1.1\" 200 -\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chapter 4\n",
    "\n",
    "# 1. dbt sources\n",
    "Welcome back to our last chapter! For this lesson, we'll be covering a different method to work with data in your data warehouse - dbt sources.\n",
    "\n",
    "## 2. What is a dbt source?\n",
    "In dbt, sources represent the ability to name and describe data loaded by the EL process. In other words, this is applying extra information to the data that is in / about to enter your data warehouse. Remember that dbt itself handles the transformation portion of the ELT process. We'll discuss these in further detail shortly, but sources are helpful in defining data lineage, data testing, and data documentation.\n",
    "\n",
    "## 3. Sources\n",
    "dbt sources are primarily present to provide data lineage information. As a reminder, data lineage describes the flow of data in a data warehouse. This helps with validation, troubleshooting, and various aspects of data trust, such as how important is this data and where did it come from. To access a given source, we use the Jinja source function. You can see in the example that instead of using a specific name or reference, we use the source function. Note that this is used in a similar way to the ref function. Note that here raw is the database schema and orders is the name of the table. In addition to providing lineage, the source option will also simplify accessing the data. This is a single method to access your tables regardless of your data warehouse instead of needing to know how to access the data directly for each type of warehouse.\n",
    "\n",
    "```sql\n",
    "select * \n",
    "from\n",
    " {{ source('raw','orders') }}\n",
    " ```\n",
    "\n",
    "## 4. Defining a source\n",
    "To define a source in dbt, we use our friend the YAML file once again. This can be the models/model_properties.yml file we've used before, or it can be any other .yml file in the models directory. Note that even though it may be named model_properties.yml, dbt really only looks for a yml file for this information. The actual definition goes in the sources section of the yml file. Name the source starting with a - name option. This is usually the database name, such as raw. We then define each source table, with a - name option under the tables: section. A quick example shows two tables defined under the raw database, phone_orders and web_orders. Note that different options are available depending on the data warehouse type. Refer to the dbt documentation for more info.\n",
    "\n",
    "```yaml\n",
    "version: 2\n",
    "sources:\n",
    "- name: raw\n",
    "tables:\n",
    "- name: phone_orders\n",
    "- name: web_orders\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "## 5. Accessing sources\n",
    "To access a source in our models, as mentioned previously, we use the source Jinja function. The source function takes two arguments, the source_name, and the table_name. The function will return the proper name to access the source table depending on the data warehouse and its configuration. A quick example shows our dbt model source that we could call all_orders. It represents a simple union of the phone_orders and web_orders fields we saw previously. Once compiled, we see that the source function is replaced by the database name dot table name. This will again vary depending on your data warehouse.\n",
    "\n",
    "\n",
    "```sql\n",
    "select * from\n",
    "{{ source('raw', 'phone_orders') }}\n",
    "UNION\n",
    "select * from\n",
    "{{ source('raw', 'web_orders') }}\n",
    "```\n",
    "\n",
    "## 6. Testing sources\n",
    "A quick note about testing - you can apply tests to sources, using the same methods that you apply to models. This includes built-in, singular, and generic / reusable tests. The tests are defined in the sources: section of the yml file, instead of the models: section. These are placed in the same yml file where the sources are defined.\n",
    "\n",
    "```yaml\n",
    "version: 2\n",
    "sources:\n",
    "- name: raw\n",
    "tables:\n",
    "- name: phone_orders\n",
    "columns:\n",
    "- name: id\n",
    "tests:\n",
    "- not_null\n",
    "- unique\n",
    "- name: web_orders\n",
    "```\n",
    "\n",
    "```yaml\n",
    "version: 2\n",
    "sources:\n",
    "- name: raw\n",
    "tables:\n",
    "- name: phone_orders\n",
    "description: >\n",
    "Sales orders by phone, daily\n",
    "columns:\n",
    "- name: id\n",
    "tests:\n",
    "- not_null\n",
    "- unique\n",
    "```\n",
    "\n",
    "## 7. Documentation\n",
    "You can also add documentation to your sources, using the same tools as with models. As with tests, this is defined in the sources: section rather than the models: section of the appropriate yml file. In this example, we've defined our source and the tests, but add a description field for the table.\n",
    "\n",
    "## 8. Let's practice!\n",
    "It's time to apply what we've learned in the coming exercises. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test includes build-in, singular and generic / reusable tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# exercice\n",
    "\n",
    "\n",
    "\n",
    "model_properties.yml\n",
    "```yml\n",
    "version: 2\n",
    "\n",
    "sources:\n",
    "  - name: raw\n",
    "    tables:\n",
    "      - name: taxi_rides\n",
    "```\n",
    "\n",
    "taxi_rides_raw.sql\n",
    "```sql\n",
    "{{ config(materialized='view')}}\n",
    "\n",
    "select * from {{ source('raw', 'taxi_rides') }}\n",
    "```\n",
    "\n",
    "```bash\n",
    "repl:~/workspace/nyc_yellow_taxi$ dbt run\n",
    "01:32:06  Running with dbt=1.5.1\n",
    "01:32:06  Unable to do partial parsing because saved manifest not found. Starting full parse.\n",
    "01:32:08  [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.\n",
    "There are 1 unused configuration paths:\n",
    "- models.nyc_yellow_taxi\n",
    "01:32:08  Found 1 model, 0 tests, 0 snapshots, 0 analyses, 313 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics, 0 groups\n",
    "01:32:08  \n",
    "01:32:08  Concurrency: 1 threads (target='dev')\n",
    "01:32:08  \n",
    "01:32:08  1 of 1 START sql view model main.taxi_rides_raw ................................ [RUN]\n",
    "01:32:08  1 of 1 OK created sql view model main.taxi_rides_raw ........................... [OK in 0.13s]\n",
    "01:32:08  \n",
    "01:32:08  Finished running 1 view model in 0 hours 0 minutes and 0.30 seconds (0.30s).\n",
    "01:32:08  \n",
    "01:32:08  Completed successfully\n",
    "01:32:08  \n",
    "01:32:08  Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1\n",
    "\n",
    "\n",
    "repl:~/workspace/nyc_yellow_taxi$ dbt test \n",
    "01:32:15  Running with dbt=1.5.1\n",
    "01:32:15  [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.\n",
    "There are 1 unused configuration paths:\n",
    "- models.nyc_yellow_taxi\n",
    "01:32:15  Found 1 model, 0 tests, 0 snapshots, 0 analyses, 313 macros, 0 operations, 0 seed files, 1 source, 0 exposures, 0 metrics, 0 groups\n",
    "01:32:15  \n",
    "01:32:15  Nothing to do. Try checking your model configs and model specification args\n",
    "repl:~/workspace/nyc_yellow_taxi$ ./datacheck \n",
    "\n",
    " VendorID  tpep_pickup_datetime  tpep_dropoff_datet   passenger_count    tolls_amount  improvement_surcha   total_amount  congestion_surcharge  airport_fee \n",
    "  int64         timestamp             timestamp            double             double            double            double            double           double    \n",
    "\n",
    "        2  2023-01-01 00:32:10   2023-01-01 00:40:36               1.0             0.0                   1.0          14.3                   2.5          0.0 \n",
    "        2  2023-01-01 00:55:08   2023-01-01 01:01:27               1.0             0.0                   1.0          16.9                   2.5          0.0 \n",
    "        2  2023-01-01 00:25:04   2023-01-01 00:37:49               1.0             0.0                   1.0          34.9                   2.5          0.0 \n",
    "        1  2023-01-01 00:03:48   2023-01-01 00:13:25               0.0             0.0                   1.0         20.85                   0.0         1.25 \n",
    "        2  2023-01-01 00:10:29   2023-01-01 00:21:19               1.0             0.0                   1.0         19.68                   2.5          0.0 \n",
    "        2  2023-01-01 00:50:34   2023-01-01 01:02:52               1.0             0.0                   1.0          27.8                   2.5          0.0 \n",
    "        2  2023-01-01 00:09:22   2023-01-01 00:19:49               1.0             0.0                   1.0         20.52                   2.5          0.0 \n",
    "        2  2023-01-01 00:27:12   2023-01-01 00:49:56               1.0             3.0                   1.0         64.44                   2.5          0.0 \n",
    "        2  2023-01-01 00:21:44   2023-01-01 00:36:40               1.0             0.0                   1.0         28.38                   2.5          0.0 \n",
    "        2  2023-01-01 00:39:42   2023-01-01 00:50:36               1.0             0.0                   1.0          19.9                   2.5          0.0 \n",
    "                                                                                                                                                     \n",
    "                                                                                                                                                     \n",
    "                                                                                                                                                     \n",
    "        2  2023-01-01 01:28:24   2023-01-01 01:56:38               2.0             0.0                   1.0          42.3                   2.5          0.0 \n",
    "        2  2023-01-01 01:25:30   2023-01-01 01:46:33               2.0             0.0                   1.0          35.6                   2.5          0.0 \n",
    "        2  2023-01-01 01:49:47   2023-01-01 02:01:27               1.0             0.0                   1.0         26.63                   2.5          0.0 \n",
    "        2  2023-01-01 01:13:11   2023-01-01 01:16:31               2.0             0.0                   1.0         14.04                   2.5          0.0 \n",
    "        2  2023-01-01 01:22:22   2023-01-01 01:33:19               1.0             0.0                   1.0         21.36                   2.5          0.0 \n",
    "        2  2023-01-01 01:37:42   2023-01-01 01:49:29               2.0             0.0                   1.0          17.8                   2.5          0.0 \n",
    "        2  2023-01-01 01:51:17   2023-01-01 02:02:07               1.0             0.0                   1.0          22.9                   2.5          0.0 \n",
    "        2  2023-01-01 01:49:24   2023-01-01 02:17:26               2.0             0.0                   1.0          33.2                   2.5          0.0 \n",
    "        1  2023-01-01 01:16:50   2023-01-01 01:23:29               2.0             0.0                   1.0          10.4                   0.0          0.0 \n",
    "        1  2023-01-01 01:26:48   2023-01-01 01:35:56               1.0             0.0                   1.0          13.9                   0.0          0.0 \n",
    "\n",
    " ? rows (>9999 rows, 20 shown)                                                                                                                     19 columns (9 shown) \n",
    "\n",
    "\n",
    "\n",
    " count_star() \n",
    "    int64     \n",
    "\n",
    "       300000 \n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
